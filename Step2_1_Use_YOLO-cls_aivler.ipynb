{"cells":[{"cell_type":"markdown","metadata":{"id":"CyurDtxqHT0o"},"source":["# **Use YOLO-cls !**"]},{"cell_type":"markdown","metadata":{"id":"WE6nWiH8-i9q"},"source":["## 0.미션\n"]},{"cell_type":"markdown","metadata":{"id":"53bSTpVT-n_Y"},"source":["### (1) 미션1\n","여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"DBjsZP8C-2Ra"},"source":["### (2) 미션2\n","데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"WkDv7UfdYOgg"},"source":["## 1.환경설정"]},{"cell_type":"markdown","metadata":{"id":"mIxbiQ8wYOcy"},"source":["* 세부 요구사항\n","    - 경로 설정 : 구글콜랩\n","        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n","        * 데이터 파일을 복사해 넣습니다.\n","        * 필요하다고 판단되는 라이브러리를 추가하세요."]},{"cell_type":"markdown","metadata":{"id":"XIjpXC-xYHh3"},"source":["### (1) 경로 설정"]},{"cell_type":"markdown","metadata":{"id":"m6qgvZMSYcoX"},"source":["* 구글 드라이브 연결"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imfft4dGGJ2E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211491440,"user_tz":-540,"elapsed":37274,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"fe116e5b-736e-457d-dc30-a4ebfc78c02e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPngJ_nwZPRC"},"outputs":[],"source":["path = '/content/drive/MyDrive/2024.10.28_미니프로젝트 4차_실습자료'"]},{"cell_type":"markdown","metadata":{"id":"SNEKwf_LY0JB"},"source":["### (2) 라이브러리 설치 및 불러오기"]},{"cell_type":"markdown","metadata":{"id":"xPwDW6e_Y0Fa"},"source":["* 라이브러리 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4dS7tW-Zwrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211497889,"user_tz":-540,"elapsed":6452,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"a101edc6-94e6-44e0-ccf1-27486373f742"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.24-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.24-py3-none-any.whl (877 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.7/877.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.24 ultralytics-thop-2.0.9\n"]}],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"Eg0gCl9Yatak"},"source":["## 2.미션1"]},{"cell_type":"markdown","metadata":{"id":"hPvTHwTmbKR5"},"source":["여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 **문제에 적합한** UltraLytics YOLO-cls 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 바꿔야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - UltraLytics YOLO-cls 모델에서 요구하는 데이터셋 폴더의 구조가 있습니다.\n","    - [UltraLytics YOLO-cls 모델의 데이터셋 구조 링크](https://docs.ultralytics.com/datasets/classify/)"]},{"cell_type":"markdown","metadata":{"id":"6rXSONrsatd5"},"source":["### (1) 데이터셋 불러오기"]},{"cell_type":"markdown","metadata":{"id":"VXLqxwNaathI"},"source":["* **세부 요구사항**\n","    - 데이터셋을 불러옵니다.\n","        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n","            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n","                - 압축 파일을 로컬에 다운로드 받아서 **어떤 구조**인지 확인하세요.\n","            2. 여러분의 얼굴 이미지 데이터셋\n","                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n","                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n","    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n","        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n","        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, zipfile"]},{"cell_type":"markdown","metadata":{"id":"6OntGw5H-C3q"},"source":["#### 1) 본인 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFq5L4aAeQHr"},"outputs":[],"source":["import os\n","import zipfile"]},{"cell_type":"code","source":["data_myFace = path + '/Datasets/Keras/image.zip'\n","data_myFace"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bH9N6RQCy24g","executionInfo":{"status":"ok","timestamp":1730211497890,"user_tz":-540,"elapsed":6,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"c636ffdf-1151-41d3-ccc6-f661b8809179"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/2024.10.28_미니프로젝트 4차_실습자료/Datasets/Keras/image.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["## Colab에 생성할 본인 얼굴 폴더 경로\n","extract_folder = '/content/my_face'\n","\n","## 위의 경로에 폴더가 없을 때 생성\n","if not os.path.exists(extract_folder) :\n","    os.makedirs(extract_folder)\n","\n","## 위의 경로에 압축을 해제\n","with zipfile.ZipFile(data_myFace, 'r') as zip_ref :\n","    file_list = zip_ref.namelist()\n","\n","    for f in file_list :\n","        if not f.endswith('/') and f.lower().endswith('.jpg') :\n","            file_name = os.path.basename(f)\n","\n","            if not file_name.startswith('._') :\n","                d_path = os.path.join(extract_folder, file_name)\n","\n","                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n","                    target.write(source.read())"],"metadata":{"id":"Gl4gJ0uAy4Ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 생성된 본인 얼굴 이미지 데이터 폴더 안의 이미지 수\n","len(os.listdir(extract_folder) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRCX6yPKzDhO","executionInfo":{"status":"ok","timestamp":1730211501766,"user_tz":-540,"elapsed":9,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"82e69ae7-d8d0-4844-a049-db345cf8be92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2451"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"fCDldok5ySsg"},"source":["#### 2) 다른 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rITP9F5qeQ5K","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1730211501766,"user_tz":-540,"elapsed":7,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"9317b2f2-8dd3-41d5-ca6c-9327b5c1e2f2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/2024.10.28_미니프로젝트 4차_실습자료/Datasets/Keras/lfw-deepfunneled.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["data_other = path + '/Datasets/Keras/lfw-deepfunneled.zip'\n","data_other"]},{"cell_type":"code","source":["## Colab에 생성할 다른 얼굴 폴더 경로\n","extract_folder = '/content/other_face'\n","\n","## 위의 경로에 폴더가 없을 때 생성\n","if not os.path.exists(extract_folder) :\n","    os.makedirs(extract_folder)\n","\n","## 위의 경로에 압축을 해제\n","with zipfile.ZipFile(data_other, 'r') as zip_ref :\n","    file_list = zip_ref.namelist()\n","\n","    for f in file_list :\n","        if not f.endswith('/') and f.lower().endswith('.jpg') :\n","            file_name = os.path.basename(f)\n","\n","            if not file_name.startswith('._') :\n","                d_path = os.path.join(extract_folder, file_name)\n","\n","                with zip_ref.open(f) as source, open(d_path, 'wb') as target :\n","                    target.write(source.read())"],"metadata":{"id":"F3IqT6-ezGPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 생성된 다른 사람 얼굴 이미지 데이터 폴더 안의 이미지 수\n","len(os.listdir(extract_folder) )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UESv3QNizHbj","executionInfo":{"status":"ok","timestamp":1730211507803,"user_tz":-540,"elapsed":4,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"6bf47924-954a-4256-dd03-6d939bf489db"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13233"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"G-TovD9FLCCL"},"source":["### (2) 데이터셋 전처리"]},{"cell_type":"markdown","metadata":{"id":"tJPBtHv8LCCL"},"source":["* **세부 요구사항**\n","    - 데이터셋을 전처리 합니다.\n","        - YOLO-cls 모델이 요구하는 폴더 구조를 만듭니다.\n","            1. Datasets라는 폴더를 생성합니다.\n","            2. Training set, Validation set, Test set(선택 사항) 각 데이터셋이 들어갈 폴더를 생성합니다.\n","            3. 각 데이터셋 폴더에 분류할 클래스의 이름을 가진 폴더를 생성합니다.\n","        - 폴더 구조에 맞게 데이터를 분배합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, glob, random, shutil, numpy"]},{"cell_type":"markdown","metadata":{"id":"-_MF4zCRie5X"},"source":["#### 1) 모델이 요하는 구조의 폴더 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTzgG1M1eR-A"},"outputs":[],"source":["import glob\n","import random\n","import shutil\n","import numpy as np\n","\n","from keras.utils import load_img, img_to_array\n","from keras.utils import image_dataset_from_directory"]},{"cell_type":"code","source":["## image_dataset_from_directory를 사용하기 위해 Colab에 폴더 생성\n","\n","# 데이터셋 폴더 생성\n","dataset_dir = '/content/Datasets'\n","train_dir = os.path.join(dataset_dir, 'train')\n","val_dir = os.path.join(dataset_dir, 'val')\n","test_dir = os.path.join(dataset_dir, 'test')\n","\n","for directory in [train_dir, val_dir, test_dir]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)"],"metadata":{"id":"-Hk8xH5q07sQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZPds1GraeJ3"},"source":["#### 2) 각 폴더에 이미지 데이터 옮기기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfVQOMf8eTkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730211514796,"user_tz":-540,"elapsed":2981,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"90ba85c1-0d0c-46bd-abdb-60b4df19f2e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터셋 분할 및 이동이 완료되었습니다.\n"]}],"source":["# 클래스 폴더 생성 (Face, OtherFace)\n","train_face_dir = os.path.join(train_dir, 'Face')\n","train_otherface_dir = os.path.join(train_dir, 'OtherFace')\n","\n","val_face_dir = os.path.join(val_dir, 'Face')\n","val_otherface_dir = os.path.join(val_dir, 'OtherFace')\n","\n","test_face_dir = os.path.join(test_dir, 'Face')\n","test_otherface_dir = os.path.join(test_dir, 'OtherFace')\n","\n","for directory in [train_face_dir, train_otherface_dir, val_face_dir, val_otherface_dir, test_face_dir, test_otherface_dir]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","# 이미지 파일을 Train, Val, Test 폴더로 분할 및 이동하는 함수 정의\n","def split_and_move_images(source_dir, train_dir, val_dir, test_dir, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n","    image_files = glob.glob(os.path.join(source_dir, '*.jpg'))\n","    random.shuffle(image_files)\n","\n","    num_images = len(image_files)\n","    num_train = int(num_images * train_ratio)\n","    num_val = int(num_images * val_ratio)\n","    num_test = num_images - num_train - num_val\n","\n","    train_files = image_files[:num_train]\n","    val_files = image_files[num_train:num_train + num_val]\n","    test_files = image_files[num_train + num_val:]\n","\n","    # 파일을 각각의 폴더로 이동\n","    for file in train_files:\n","        shutil.copy(file, os.path.join(train_dir))\n","    for file in val_files:\n","        shutil.copy(file, os.path.join(val_dir))\n","    for file in test_files:\n","        shutil.copy(file, os.path.join(test_dir))\n","\n","# my_face 폴더의 이미지를 'Face' 클래스로, other_face 폴더의 이미지를 'OtherFace' 클래스로 분할하여 이동\n","split_and_move_images('/content/my_face', train_face_dir, val_face_dir, test_face_dir)\n","split_and_move_images('/content/other_face', train_otherface_dir, val_otherface_dir, test_otherface_dir)\n","\n","print(\"데이터셋 분할 및 이동이 완료되었습니다.\")\n"]},{"cell_type":"code","source":["# 각 항목의 수를 나타내는 코드 추가\n","def count_images(directory):\n","    count = len(glob.glob(os.path.join(directory, '*.jpg')))\n","    return count\n","\n","print(\"\\n각 폴더의 이미지 개수:\")\n","print(f\"Train/Face: {count_images(train_face_dir)}\")\n","print(f\"Train/OtherFace: {count_images(train_otherface_dir)}\")\n","print(f\"Val/Face: {count_images(val_face_dir)}\")\n","print(f\"Val/OtherFace: {count_images(val_otherface_dir)}\")\n","print(f\"Test/Face: {count_images(test_face_dir)}\")\n","print(f\"Test/OtherFace: {count_images(test_otherface_dir)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaq23oyZF7-F","executionInfo":{"status":"ok","timestamp":1730211514796,"user_tz":-540,"elapsed":4,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"e8d4036b-4d76-4b5a-c623-b78065e66da5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","각 폴더의 이미지 개수:\n","Train/Face: 1470\n","Train/OtherFace: 7939\n","Val/Face: 490\n","Val/OtherFace: 2646\n","Test/Face: 491\n","Test/OtherFace: 2648\n"]}]},{"cell_type":"markdown","metadata":{"id":"w59u5Dtnrh5h"},"source":["## 3.미션2"]},{"cell_type":"markdown","metadata":{"id":"JHu91EoOrh2Q"},"source":["데이터셋의 폴더 구조를 **학습에 적합한 형태**로 만들었다면, **사전 학습된 UltraLytics YOLO-cls 모델**에 Transfer Learning을 수행합니다.\n","\n","- 1) UltraLytics YOLO-cls 모델 선택\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)\n","- 2) 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)\n","- 3) 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/#inference-arguments)\n","- 4) 해당 UltraLytics YOLO-cls 모델을 **반드시** 저장합니다.\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"markdown","metadata":{"id":"AygPItZba0TI"},"source":["#### (1) UltraLytics YOLO-cls 모델 선택"]},{"cell_type":"markdown","metadata":{"id":"E7zOy5GfbMTR"},"source":["* **세부 요구사항**\n","    - 세부 모델로 n, s, m, l, x가 있습니다. n가 가장 빠르고, x가 가장 연산량이 많습니다.\n","    - [UltraLytics YOLO-cls 모델 링크](https://docs.ultralytics.com/tasks/classify/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULEjDkdUGhCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730212115930,"user_tz":-540,"elapsed":601136,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"c79692ec-329e-4782-828d-2dd197fb2daa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.52M/5.52M [00:00<00:00, 160MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=/content/Datasets, epochs=10, time=None, patience=100, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 9409 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 3136 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3139 images in 2 classes ✅ \n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 10                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n","YOLO11n-cls summary: 151 layers, 1,533,666 parameters, 1,533,666 gradients, 3.3 GFLOPs\n","Transferred 234/236 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 225MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Datasets/train... 9409 images, 0 corrupt: 100%|██████████| 9409/9409 [00:02<00:00, 3445.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Datasets/train.cache\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/val... 3136 images, 0 corrupt: 100%|██████████| 3136/3136 [00:00<00:00, 3203.51it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Datasets/val.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 64 train, 64 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/classify/train\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/10     0.153G     0.6181         16         64:   3%|▎         | 17/589 [00:02<00:59,  9.62it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["       1/10     0.153G     0.6397         16         64:   4%|▎         | 21/589 [00:02<01:08,  8.32it/s]\n","100%|██████████| 755k/755k [00:00<00:00, 91.0MB/s]\n","       1/10     0.153G     0.1093          1         64: 100%|██████████| 589/589 [00:57<00:00, 10.21it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:04<00:00, 21.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/10     0.145G    0.02048          1         64: 100%|██████████| 589/589 [00:53<00:00, 11.10it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:04<00:00, 21.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/10     0.145G   0.008081          1         64: 100%|██████████| 589/589 [00:49<00:00, 11.90it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:07<00:00, 12.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/10     0.145G   0.005044          1         64: 100%|██████████| 589/589 [00:47<00:00, 12.48it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:06<00:00, 16.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/10     0.145G    0.01915          1         64: 100%|██████████| 589/589 [00:49<00:00, 11.87it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:04<00:00, 22.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/10     0.145G   0.002437          1         64: 100%|██████████| 589/589 [00:49<00:00, 11.87it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:06<00:00, 15.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/10     0.145G     0.0137          1         64: 100%|██████████| 589/589 [00:47<00:00, 12.34it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:06<00:00, 15.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/10     0.145G    0.01412          1         64: 100%|██████████| 589/589 [00:49<00:00, 11.89it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:04<00:00, 21.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/10     0.145G    0.01497          1         64: 100%|██████████| 589/589 [00:50<00:00, 11.72it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:06<00:00, 16.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/10     0.145G  0.0003282          1         64: 100%|██████████| 589/589 [00:47<00:00, 12.31it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:06<00:00, 14.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","10 epochs completed in 0.158 hours.\n","Optimizer stripped from runs/classify/train/weights/last.pt, 3.2MB\n","Optimizer stripped from runs/classify/train/weights/best.pt, 3.2MB\n","\n","Validating runs/classify/train/weights/best.pt...\n","Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLO11n-cls summary (fused): 112 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 9409 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 3136 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3139 images in 2 classes ✅ \n"]},{"output_type":"stream","name":"stderr","text":["               classes   top1_acc   top5_acc: 100%|██████████| 98/98 [00:05<00:00, 19.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n","Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train\u001b[0m\n"]}],"source":["# prompt:  UltraLytics YOLO-cls 모델\n","\n","from ultralytics import YOLO\n","\n","# 모델 학습\n","model = YOLO('yolo11n-cls.pt')  # 'n', 's', 'm', 'l', 'x' 중 선택\n","results = model.train(data='/content/Datasets', epochs=10, imgsz=64, device=0) # 데이터셋 경로, epochs 수, 이미지 크기 설정"]},{"cell_type":"markdown","metadata":{"id":"X7rqg7bda6Uz"},"source":["#### (2) UltraLytics YOLO-cls 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"48UKFtS6bc9b"},"source":["* **세부 요구사항**\n","    - 선택한 UltraLytics YOLO-cls 모델로 학습을 진행합니다.\n","    - [UltraLytics YOLO 학습 명령어 링크](https://docs.ultralytics.com/modes/train/#train-settings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"891Qn60yGhCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730212126590,"user_tz":-540,"elapsed":10664,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"6831a92f-6f0a-4d0e-e30a-afa915a51ff1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.24 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","YOLO11n-cls summary (fused): 112 layers, 1,528,586 parameters, 0 gradients, 3.2 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/Datasets/train... found 9409 images in 2 classes ✅ \n","\u001b[34m\u001b[1mval:\u001b[0m /content/Datasets/val... found 3136 images in 2 classes ✅ \n","\u001b[34m\u001b[1mtest:\u001b[0m /content/Datasets/test... found 3139 images in 2 classes ✅ \n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Datasets/val... 3136 images, 0 corrupt: 100%|██████████| 3136/3136 [00:00<?, ?it/s]\n","               classes   top1_acc   top5_acc: 100%|██████████| 196/196 [00:07<00:00, 26.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n","Speed: 0.0ms preprocess, 1.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n","Top-1 Accuracy: 1.0\n","Top-5 Accuracy: 1.0\n"]}],"source":["# 모델 검증\n","metrics = model.val()  # 학습된 모델의 정확도를 검증\n","print(f\"Top-1 Accuracy: {metrics.top1}\")\n","print(f\"Top-5 Accuracy: {metrics.top5}\")"]},{"cell_type":"markdown","metadata":{"id":"UsxBhoAubn2u"},"source":["#### (3) UltraLytics YOLO-cls 추론"]},{"cell_type":"markdown","metadata":{"id":"wPtTHcnbbn2u"},"source":["* **세부 요구사항**\n","    - 학습이 완료되면 추론을 진행합니다.\n","    - [UltraLytics YOLO 추론 명령어 링크](https://docs.ultralytics.com/modes/predict/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ffQ725eGhC0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730212126590,"user_tz":-540,"elapsed":6,"user":{"displayName":"기린","userId":"09984176106698290582"}},"outputId":"b1cf56a7-4afe-4054-cc80-00d13701ff1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'source' is missing. Using 'source=/usr/local/lib/python3.10/dist-packages/ultralytics/assets'.\n","\n","image 1/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 64x64 OtherFace 1.00, Face 0.00, 8.9ms\n","image 2/2 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg: 64x64 OtherFace 1.00, Face 0.00, 8.6ms\n","Speed: 12.9ms preprocess, 8.7ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 64)\n","\n","추론 결과:\n","[ultralytics.engine.results.Results object with attributes:\n","\n","boxes: None\n","keypoints: None\n","masks: None\n","names: {0: 'Face', 1: 'OtherFace'}\n","obb: None\n","orig_img: array([[[119, 146, 172],\n","        [121, 148, 174],\n","        [122, 152, 177],\n","        ...,\n","        [161, 171, 188],\n","        [160, 170, 187],\n","        [160, 170, 187]],\n","\n","       [[120, 147, 173],\n","        [122, 149, 175],\n","        [123, 153, 178],\n","        ...,\n","        [161, 171, 188],\n","        [160, 170, 187],\n","        [160, 170, 187]],\n","\n","       [[123, 150, 176],\n","        [124, 151, 177],\n","        [125, 155, 180],\n","        ...,\n","        [161, 171, 188],\n","        [160, 170, 187],\n","        [160, 170, 187]],\n","\n","       ...,\n","\n","       [[183, 182, 186],\n","        [179, 178, 182],\n","        [180, 179, 183],\n","        ...,\n","        [121, 111, 117],\n","        [113, 103, 109],\n","        [115, 105, 111]],\n","\n","       [[165, 164, 168],\n","        [173, 172, 176],\n","        [187, 186, 190],\n","        ...,\n","        [102,  92,  98],\n","        [101,  91,  97],\n","        [103,  93,  99]],\n","\n","       [[123, 122, 126],\n","        [145, 144, 148],\n","        [176, 175, 179],\n","        ...,\n","        [ 95,  85,  91],\n","        [ 96,  86,  92],\n","        [ 98,  88,  94]]], dtype=uint8)\n","orig_shape: (1080, 810)\n","path: '/usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg'\n","probs: ultralytics.engine.results.Probs object\n","save_dir: 'runs/classify/train3'\n","speed: {'preprocess': 12.711286544799805, 'inference': 8.852481842041016, 'postprocess': 0.16689300537109375}, ultralytics.engine.results.Results object with attributes:\n","\n","boxes: None\n","keypoints: None\n","masks: None\n","names: {0: 'Face', 1: 'OtherFace'}\n","obb: None\n","orig_img: array([[[44, 51, 76],\n","        [43, 50, 75],\n","        [41, 48, 73],\n","        ...,\n","        [20, 18, 54],\n","        [18, 16, 52],\n","        [17, 15, 51]],\n","\n","       [[44, 51, 76],\n","        [43, 50, 75],\n","        [41, 48, 73],\n","        ...,\n","        [20, 18, 54],\n","        [18, 16, 52],\n","        [18, 16, 52]],\n","\n","       [[44, 51, 76],\n","        [43, 50, 75],\n","        [41, 48, 73],\n","        ...,\n","        [21, 18, 57],\n","        [19, 16, 55],\n","        [18, 15, 54]],\n","\n","       ...,\n","\n","       [[53, 44, 40],\n","        [52, 43, 39],\n","        [51, 42, 38],\n","        ...,\n","        [50, 50, 38],\n","        [51, 51, 39],\n","        [52, 52, 40]],\n","\n","       [[53, 44, 40],\n","        [52, 43, 39],\n","        [51, 42, 38],\n","        ...,\n","        [50, 50, 38],\n","        [51, 51, 39],\n","        [52, 52, 40]],\n","\n","       [[53, 44, 40],\n","        [52, 43, 39],\n","        [51, 42, 38],\n","        ...,\n","        [49, 49, 37],\n","        [51, 51, 39],\n","        [52, 52, 40]]], dtype=uint8)\n","orig_shape: (720, 1280)\n","path: '/usr/local/lib/python3.10/dist-packages/ultralytics/assets/zidane.jpg'\n","probs: ultralytics.engine.results.Probs object\n","save_dir: 'runs/classify/train3'\n","speed: {'preprocess': 13.006448745727539, 'inference': 8.62264633178711, 'postprocess': 0.08416175842285156}]\n"]}],"source":["results = model.predict()  # 테스트 데이터셋에서 추론 수행\n","print(\"\\n추론 결과:\")\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"2ytKJsOUGhC0"},"source":["#### (4) UltraLytics YOLO-cls 모델 저장"]},{"cell_type":"markdown","metadata":{"id":"VkC4WP-8cA7g"},"source":["* **세부 요구사항**\n","    - 모델을 **반드시** 저장하세요.\n","    - .pt 형태로 Colab에 저장이 될 것입니다. 해당 파일을 **로컬에 다운로드** 하세요."]},{"cell_type":"code","source":["## .keras로 저장해야 안전\n","model.save('YOLO_1029.pt')"],"metadata":{"id":"yAeJ2tLlQU3Y"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}